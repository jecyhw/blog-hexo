# 中间件比赛初赛总结

##队伍介绍

队伍名称： L\*\*J\*\*Y=+∞ 

队长：杨慧伟  昵称： jecyang

队员：李世雄  昵称： 千手柱间

队员：金融通  昵称：King1993

来自中国科学院的一支队伍

## 赛题描述

**赛题描述：**
Apache RocketMQ作为的一款分布式的消息中间件，历年双十一承载了万亿级的消息流转，为业务方提供高性能低延迟的稳定可靠的消息服务。随着业务的逐步发展和云上的输出，单机队列数量的逐步增加，给RocketMQ带来了新的挑战。复赛的题目要求设计一个单机百万队列以上的存储引擎，单机内存有限，需要充分利用数据结构与存储技术，最大化吞吐量。

**题目描述：**
持续更新地址：https://code.aliyun.com/middlewarerace2018/queuerace2018

**题目内容**
实现一个进程内的队列引擎，单机可支持100万队列以上。

**语言限定**
JAVA和C++

**程序目标**
仔细阅读demo项目中的QueueStore，DefaultQueueStoreImpl，DemoTester三个类。

你的coding目标是重写DefaultQueueStoreImpl，并实现以下接口: abstract void put(String queueName, String message); abstract Collection get(String queueName, long offset, long num);

**参赛方法说明**
在阿里天池找到"中间件性能挑战赛"，并报名参加
在code.aliyun.com注册一个账号，并新建一个仓库名，并将大赛官方账号middlewarerace2018添加为项目成员，权限为reporter
fork或者拷贝本仓库的代码到自己的仓库，并实现自己的逻辑
在天池提交成绩的入口，提交自己的仓库git地址，等待评测结果
坐等每天10点排名更新
**测试环境描述**
测试环境为4c8g的ECS，限定使用的最大JVM大小为4GB(-Xmx4g)。带一块500G左右大小的SSD磁盘。

**程序校验逻辑**
校验程序分为三个阶段： 1.发送阶段 2.索引校验阶段 3.顺序消费阶段 请详细阅读DemoTester以理解评测程序的逻辑。

**程序校验规模说明**
1.各个阶段线程数在20~30左右 2.发送阶段：消息大小在50字节左右，消息条数在20亿条左右，也即发送总数据在100G左右 3.索引校验阶段：会对所有队列的索引进行随机校验；平均每个队列会校验1~2次； 4.顺序消费阶段：挑选20%的队列进行全部读取和校验； 5.发送阶段最大耗时不能超过1800s；索引校验阶段和顺序消费阶段加在一起，最大耗时也不能超过1800s；超时会被判断为评测失败。

**排名规则**
在结果校验100%正确的前提下，按照平均tps从高到低来排名

**第二/三方库规约**
仅允许依赖JavaSE 8 包含的lib
可以参考别人的实现，拷贝少量的代码
我们会对排名靠前的代码进行review，如果发现大量拷贝别人的代码，将扣分

**作弊说明**
所有消息都应该进行按实际发送的信息进行存储，可以压缩，但不能伪造。 如果发现有作弊行为，比如通过hack评测程序，绕过了必须的评测逻辑，则程序无效，且取消参赛资格。


##前期方案设计
###发送阶段思路
百万队列，每个消息50字节算，每个队列一个消息就是50M，这样一个队列两条消息之间的距离就是50M。
刚开始的思路就是对队列进行分组，线程聚集消息并对分组进行管理和落盘，每个分组一个消息文件，以及二级消息索引文件（同线程下的分组可共享）。
程序给每个queueName分配一个唯一的queueId（采用自增方式）。
每个写入线程中有一个BlockingQueue用来聚集消息，发送线程发送队列消息时，通过ququeId对写入线程数求余就可以找到对应的写入线程，就可以将消息放入写入线程的队列中。
写入线程从队列中拉取消息，用queueId对分组数求余就能找到对应的分组，再将消息放到对应的分组中。

下图是一个8个队列，分成4个组，2个二级消息索引文件，有2个写入线程的示例，图中序号代表其id号。
![图1](https://raw.githubusercontent.com/jecyhw/blog-hexo/master/1.png)

分组数、二级索引文件数、写入线程数必须从大到小，且是倍数关系，才能保证整个过程是线程安全的，这样每个队列的消息只会落到唯一的线程下的唯一分组中，同一个分组只会被同一个线程访问，也就是消息聚集到写入线程的BlockingQueue之后，后续的落盘都是线程内安全的。

消息文件的存储格式为： |Len(msg1)|Byte(msg1) |Len(msg2)|Byte(msg2) |Len(msg3)|Byte(msg3) |…|
Len(msg)表示消息长度，Byte(msg)表示消息字节。

消息的查找采用了两级索引。二级索引记录消息在消息文件中的偏移，并且给每个队列的消息进行逻辑分组，二级索引存放在文件中。一级索引记录二级索引文件中每个分组的偏移，一级索引是存放在内存中。
举个简单例子说明下，假设二级索引同一个队列每4条消息为一组，整个模型如下图。
![图2](https://raw.githubusercontent.com/jecyhw/blog-hexo/master/2.png)

###校验和消费阶段
下图展示了逻辑分组为4，get队列offset=5，num=2的查找示例。
![图3](https://raw.githubusercontent.com/jecyhw/blog-hexo/master/3.png)

###总结
如果百万队列分成了1024个组，8个二级索引文件，8个写入线程，每个队列80条消息是一个逻辑分组。

1个分组大概1024个队列、每个队列2000条消息、每个消息 50字节加消息长度（采用变长编码），消息文件大小就是100M，二级索引大小就是8M，如果逻辑分组内使用相对偏移（3个字节）加一个起始绝对偏移（4字节），这样大小就是6.4M。

1个二级索引文件被128个组共享，文件大小是819.2M。

1个队列2000条消息，有25个逻辑分组，一级索引需要100字节，百万队列需要100M。

**优点：** 不限制于评测程序的场景，可以适用于随机发送场景，占用内存少，完全顺写文件，队列可扩展。

**缺点：** 读取慢，读取一条消息需要2次IOPS，读取10条消息最多需要12次IOPS（跨逻辑分组需要多1次IOPS），由于二级索引对队列消息建立了一个逻辑分组，那么可以通过计算读取一块来减少IOPS。上分难。

这样设计还有一个想法是想利用磁盘来做物理聚合。

##后期版本思路
###发送阶段
利用58字节这个数据特性，将消息按固定数进行聚合，且依次按照queueId顺序写入文件。

聚合的消息数为20，那么所有队列聚合20条消息大小就是1000000*20*58≈1.1g。
申请2块1.1g的对外内存，依次slice 20*58个字节给给个队列，等所有队列都聚合了20条消息，将整个1.1g的消息落盘，另外一块1.1g内存作为交换使用。
落盘操作时使用单独的异步写线程来做的。这样的优势是可以省去索引，因为所有队列的消息在文件中都是有序的，有offset直接就能在文件中进行定位。消息的在文件中的格式如下图：
![图4](https://raw.githubusercontent.com/jecyhw/blog-hexo/master/4.png)

消息存储采用了单文件方式，写入线程每次将消息追加到文件中。
###校验阶段
直接使用FileChannel在校验线程中读取消息
###消费阶段
消费阶段使用生产者-消费者模型，读取线程（生产者）异步读取消息到缓冲区，消费线程（消费者）从缓冲区读取消息，如下图所示。每个读取线程负责一定队列的读取。
![图5](https://raw.githubusercontent.com/jecyhw/blog-hexo/master/5.png)

队列缓冲区主要数据结构如下图所示。消费阶段是校验10%的队列，消费复用发送阶段内存，这样每个队列缓冲区大小就是2*10*(20*58)。
![图6](https://raw.githubusercontent.com/jecyhw/blog-hexo/master/6.png)

> 消费线程get需要满足getIdx<putIdx，每消费20条消息，自增1。
> 读取线程put需要满足putIdx-getIdx<20，每次读取20条消息。
> 不满足条件，消费和读取线程采用自旋方式等待。

消费阶段如何将消费队列分配给读取线程，先对所有的消费队列按queueId排序，因为每个队列的消息是每20条消息按queueId依次在文件中排列。
然后将消费队列分段给读取线程，每个读取线程负责自己段内的队列消息的读取。
下图是个简单的例子，有8个消费队列已经按照ququeId排好序，2个读取线程，前4个队列分配给第1个读取线程，后4个队列分配给第2个读取线程。
![图7](https://raw.githubusercontent.com/jecyhw/blog-hexo/master/7.png)

这样保证了每个读取线程读取的块是连续的，然后采用mmap读取，一次map的大小为400*20*58bytes≈400KB。

这种思路能避免一定量的非消费队列消息的读取，尤其是当消费队列密集的时候优势越大。

三个阶段耗时：发送阶段耗时基本稳定在600s出头，检验阶段耗时在130~170s，消费阶段耗时基本稳定在275s左右。

###优化点
